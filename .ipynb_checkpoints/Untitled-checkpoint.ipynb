{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5b797c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e1bf493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c41f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def refine_spindle_list(list_of_spindles, target = False):\n",
    "    refined_spindle_list = []\n",
    "    for spindle in list_of_spindles:\n",
    "        start = spindle[0]/(100)\n",
    "        end = spindle[1]/(100)\n",
    "        if ((end-start) < 0.3 and not target):\n",
    "            continue\n",
    "        else:\n",
    "            refined_spindle_list.append((start, end))\n",
    "\n",
    "    return refined_spindle_list\n",
    "\n",
    "\n",
    "\n",
    "def iou(out,tar):\n",
    "    out_box_start = out[0]\n",
    "    out_box_end = out[1]\n",
    "\n",
    "    tar_box_start = tar[0]\n",
    "    tar_box_end = tar[1]\n",
    "\n",
    "    overlap_start = max(out_box_start, tar_box_start)\n",
    "    overlap_end = min(out_box_end, tar_box_end)\n",
    "    union_start = min(out_box_start, tar_box_start)\n",
    "    union_end = max(out_box_end, tar_box_end)\n",
    "\n",
    "    return ((overlap_end - overlap_start)/(union_end-union_start))\n",
    "\n",
    "def overlap(out, tar, threshold):\n",
    "    out_box_start = out[0]\n",
    "    out_box_end = out[1]\n",
    "\n",
    "    tar_box_start = tar[0]\n",
    "    tar_box_end = tar[1]\n",
    "\n",
    "    overlap_start = max(out_box_start, tar_box_start)\n",
    "    overlap_end = min(out_box_end, tar_box_end)\n",
    "    union_start = min(out_box_start, tar_box_start)\n",
    "    union_end = max(out_box_end, tar_box_end)\n",
    "\n",
    "    if (overlap_end - overlap_start) >= (threshold * (tar_box_end-tar_box_start)):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e1475a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(outputs, targets):\n",
    "    \n",
    "    # Loop through batches to compute F1 score through training.\n",
    "\n",
    "    \n",
    "    F1_list = []\n",
    "    temp_tp = 0\n",
    "    total_spindle_count = 0\n",
    "    total_pred_count = 0\n",
    "\n",
    "    \n",
    "    \n",
    "    for i in range(outputs.shape[0]):\n",
    "\n",
    "        pred = out_to_vector(outputs[i,:,:].cpu())\n",
    "\n",
    "        pred_spindles = vector_to_spindle_list(pred)\n",
    "        #print(len(pred_spindles))\n",
    "\n",
    "        #pred_spindles = refine_spindle_list(pred_spindles)\n",
    "        #print(len(pred_spindles))\n",
    "\n",
    "        \n",
    "        TP = 0\n",
    "\n",
    "        target = targets[i]\n",
    "        t_spindles = vector_to_spindle_list(target.cpu())\n",
    "        #t_spindles = refine_spindle_list(t_spindles)\n",
    "\n",
    "        total_spindle_count += len(t_spindles)\n",
    "        batch_spindle_count = len(t_spindles)\n",
    "\n",
    "        if len(t_spindles) == 0:\n",
    "            spindle = False\n",
    "            for l, sample in enumerate(target):\n",
    "                if sample == 1:\n",
    "                    spindle = True\n",
    "                    print(l)\n",
    "            if spindle:\n",
    "                print('not found')\n",
    "                print(vector_to_spindle_list(target.cpu(), debug = True))\n",
    "                print(len(target))\n",
    "        batch_pred_count = len(pred_spindles)\n",
    "        for k in range(len(t_spindles)):\n",
    "            tar_box = t_spindles[k]\n",
    "            #print(tar_box)\n",
    "            \n",
    "            best_match = -1\n",
    "\n",
    "            if len(pred_spindles) == 0:\n",
    "                continue\n",
    "            \n",
    "            for j,out_box in enumerate(pred_spindles):\n",
    "\n",
    "                if iou(out_box, tar_box) > iou(pred_spindles[best_match], tar_box):\n",
    "                    best_match = j\n",
    "            #print(pred_spindles[best_match])\n",
    "            #print(tar_box)\n",
    "            if iou(pred_spindles[best_match],tar_box) > 0.2:\n",
    "                TP +=1\n",
    "            \n",
    "\n",
    "        FP = batch_pred_count - TP\n",
    "        FN = batch_spindle_count - TP\n",
    "        \n",
    "        if (TP + FP) == 0:\n",
    "            PRECISION = TP\n",
    "        else:\n",
    "            PRECISION = (TP)/(TP + FP)\n",
    "        \n",
    "        RECALL = (TP)/(TP+FN)\n",
    "\n",
    "        if (PRECISION + RECALL) == 0:\n",
    "            F1_list.append(0)\n",
    "        else:\n",
    "            F1_list.append((2 * PRECISION * RECALL)/(PRECISION + RECALL))\n",
    "        \n",
    "        temp_tp += TP\n",
    "\n",
    "\n",
    "    F1_list = np.asarray(F1_list)\n",
    "    #print(\"F1 MEAN:\", np.mean(F1_list), \" F1 STD:\", np.std(F1_list), \" TP:\", temp_tp, \" FP:\", FP, \" Number of spindles:\", total_spindle_count)\n",
    "    return (np.mean(F1_list), np.std(F1_list), temp_tp, FP, total_spindle_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b6caf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Loading data, setting up GPU use, setting up variables for model training\n",
    "def main(BATCH_SIZE = 64, EPOCHS = 801):\n",
    "    dataset_train = MODA_proc(input_path = '/scratch/s174411/full_segments/TRAIN/input/', label_path = '/scratch/s174411/full_segments/TRAIN/labels/')\n",
    "    dataset_val = MODA_proc(input_path = '/scratch/s174411/full_segments/VAL/input/', label_path = '/scratch/s174411/full_segments/VAL/labels/')\n",
    "\n",
    "    data_loader_train = DataLoader(dataset_train, batch_size=BATCH_SIZE, shuffle=True, num_workers=6)\n",
    "    data_loader_val = DataLoader(dataset_val, batch_size=BATCH_SIZE, shuffle=True, num_workers=6)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    net = u_net_backbone()\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda:0\"\n",
    "        # if torch.cuda.device_count() > 1:\n",
    "        #     print(torch.cuda.device_count(), \" GPU's GIVEN\")\n",
    "        #     net = nn.DataParallel(net)\n",
    "        # else:\n",
    "        #     print(device)\n",
    "        net.to(device)\n",
    "\n",
    "    criterion = GeneralizedDiceLoss()\n",
    "    optimizer = optim.Adam(net.parameters(), lr=0.005)\n",
    "\n",
    "    training_loss = []\n",
    "    validation_loss = []\n",
    "    for j, epoch in enumerate(range(EPOCHS)):  # loop over the dataset multiple times\n",
    "        net.train()\n",
    "\n",
    "        running_loss = []\n",
    "        f1_mean_run = []\n",
    "        f1_std_run = []\n",
    "        TP_run = []\n",
    "        FP_run = []\n",
    "        total_spindle_run = []\n",
    "        for i, batch in enumerate(data_loader_train):\n",
    "            \n",
    "                \n",
    "            model_input, labels = batch\n",
    "            model_input = model_input.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(model_input)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss.append(loss.item())\n",
    "\n",
    "            if (epoch % 100 == 0):\n",
    "                f1_mean, f1_std, TP, FP, total_spindle_count = f1_score(outputs, labels)\n",
    "                f1_mean_run.append(f1_mean)\n",
    "                f1_std_run.append(f1_std)\n",
    "                TP_run.append(TP)\n",
    "                FP_run.append(FP)\n",
    "                total_spindle_run.append(total_spindle_count)\n",
    "\n",
    "        print(f\"EPOCH:{epoch}\")\n",
    "        print(\"TRAINING\")\n",
    "        print(\"Loss: \", round(sum(running_loss)/len(running_loss), 6))\n",
    "        training_loss.append(sum(running_loss)/len(running_loss))\n",
    "        \n",
    "        if (epoch % 100 == 0):\n",
    "            print(\"F1 MEAN:\", round(sum(f1_mean_run)/len(f1_mean_run), 6), \" F1 STD:\", round(sum(f1_std_run)/len(f1_std_run), 6), \" TP:\", sum(TP_run), \" FP:\", sum(FP_run),\n",
    "                \" Number of spindles:\", sum(total_spindle_run))\n",
    "\n",
    "        net.eval()\n",
    "        \n",
    "        running_loss = []\n",
    "        print(\"VALIDATION\")\n",
    "        running_loss = []\n",
    "        f1_mean_run = []\n",
    "        f1_std_run = []\n",
    "        TP_run = []\n",
    "        FP_run = []\n",
    "        total_spindle_run = []\n",
    "        for i, batch in enumerate(data_loader_val): \n",
    "            model_input, labels = batch\n",
    "            model_input = model_input.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = net(model_input)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss.append(loss.item())\n",
    "\n",
    "            if (epoch % 100 == 0):\n",
    "                f1_mean, f1_std, TP, FP, total_spindle_count = f1_score(outputs, labels)\n",
    "                f1_mean_run.append(f1_mean)\n",
    "                f1_std_run.append(f1_std)\n",
    "                TP_run.append(TP)\n",
    "                FP_run.append(FP)\n",
    "                total_spindle_run.append(total_spindle_count)\n",
    "\n",
    "\n",
    "        print(\"Loss: \", round(sum(running_loss)/len(running_loss), 6))\n",
    "        if (epoch % 100 == 0):\n",
    "            print(loss.item())\n",
    "            print(\"F1 MEAN:\", round(sum(f1_mean_run)/len(f1_mean_run), 6), \" F1 STD:\", round(sum(f1_std_run)/len(f1_std_run), 6), \" TP:\", sum(TP_run), \" FP:\", sum(FP_run),\n",
    "                \" Number of spindles:\", sum(total_spindle_run))\n",
    "        print(\"\")\n",
    "        \n",
    "        validation_loss.append(sum(running_loss)/len(running_loss))\n",
    "\n",
    "def out_to_vector(output):\n",
    "    moving_avg = 42\n",
    "    s = moving_avg - 1\n",
    "    vector = F.pad(output, (s // 2, s // 2 + s % 2), mode='constant', value=0)\n",
    "\n",
    "    vector_smoothed =  F.avg_pool1d(vector, moving_avg, stride=1)\n",
    "    vector_softmax = F.softmax(vector_smoothed, dim=1)\n",
    "    top_p, top_class = vector_softmax.topk(1, dim = 0)\n",
    "\n",
    "    return top_class[0]\n",
    "\n",
    "\n",
    "def vector_to_spindle_list(vector, debug = False):\n",
    "    \n",
    "    prev_class = 0\n",
    "    list_of_spindles = []\n",
    "    vector = vector.numpy()\n",
    "    for i, instance_class in enumerate(vector):\n",
    "        if (instance_class == 1 and prev_class == 1):\n",
    "            prev_class = 1\n",
    "            if (i+1 == len(vector)):\n",
    "                spindle.append(i)\n",
    "                list_of_spindles.append(spindle)\n",
    "            continue\n",
    "\n",
    "        if (instance_class == 1 and prev_class == 0):\n",
    "            spindle = []\n",
    "            spindle.append(i)\n",
    "            prev_class = 1\n",
    "            continue\n",
    "\n",
    "        if (instance_class == 0 and prev_class == 1):\n",
    "            spindle.append(i)\n",
    "            list_of_spindles.append(spindle)\n",
    "            prev_class = 0\n",
    "            continue\n",
    "\n",
    "        prev_class = 0\n",
    "    return list_of_spindles\n",
    "        \n",
    "    #print(vector)\n",
    "\n",
    "        \n",
    "\n",
    "main()\n",
    "#torch.save(net, '/home/marius/Documents/OneDrive/MSc/StartUP/Code/m1_stats_features.pt')\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e16619",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
